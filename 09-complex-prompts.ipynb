{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbfd1a5c",
   "metadata": {},
   "source": [
    "# Chapter 9: Building Complex Prompts\n",
    "\n",
    "**Scenario:** You are building a specific tool, like a **Trip Planner** or a **Game Rule Assistant**. A simple one-line prompt isn't enough. You need to combine Rules, Context, Examples, and User Data into one big \"Mega-Prompt\".\n",
    "\n",
    "In this notebook, you will learn:\n",
    "- üèóÔ∏è **The Architecture**: Breaking a big prompt into blocks (Context, Rules, Data).\n",
    "- üîß **Variables**: Using Python to insert user data safely.\n",
    "- üìú **Reference Material**: Answering questions based on specific texts (like Game Rules).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9e5f2f",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Standard setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68f1e409",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T19:32:35.307939Z",
     "iopub.status.busy": "2025-12-16T19:32:35.307646Z",
     "iopub.status.idle": "2025-12-16T19:32:36.242868Z",
     "shell.execute_reply": "2025-12-16T19:32:36.242054Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install tools\n",
    "!pip install -q litellm python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8b024a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T19:32:36.245513Z",
     "iopub.status.busy": "2025-12-16T19:32:36.245334Z",
     "iopub.status.idle": "2025-12-16T19:32:37.637179Z",
     "shell.execute_reply": "2025-12-16T19:32:37.636653Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from litellm import completion\n",
    "import litellm\n",
    "import logging\n",
    "\n",
    "# Suppress noisy debug logs\n",
    "litellm.suppress_debug_info = True\n",
    "logging.getLogger(\"litellm\").setLevel(logging.CRITICAL)\n",
    "\n",
    "load_dotenv()\n",
    "MODEL_NAME = os.getenv('DEFAULT_MODEL', 'gemini/gemini-2.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47b2a168",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T19:32:37.638511Z",
     "iopub.status.busy": "2025-12-16T19:32:37.638384Z",
     "iopub.status.idle": "2025-12-16T19:32:37.640728Z",
     "shell.execute_reply": "2025-12-16T19:32:37.640388Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_completion(prompt, system_prompt=None, temperature=0.0, max_tokens=1024):\n",
    "    messages = []\n",
    "    if system_prompt:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    \n",
    "    response = completion(\n",
    "        model=MODEL_NAME,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811488b3",
   "metadata": {},
   "source": [
    "## 2. The Anatomy of a Mega-Prompt\n",
    "\n",
    "Complex prompts are easier if you build them in blocks. \n",
    "Think of it like LEGO bricks:\n",
    "\n",
    "1.  **Role**: Who is the AI?\n",
    "2.  **Context**: What is the goal?\n",
    "3.  **Rules**: What are the limits?\n",
    "4.  **Examples**: Show, don't just tell.\n",
    "5.  **Data**: The user's input.\n",
    "\n",
    "Let's build **\"TravelBot\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43a6e619",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T19:32:37.641908Z",
     "iopub.status.busy": "2025-12-16T19:32:37.641822Z",
     "iopub.status.idle": "2025-12-16T19:32:38.839351Z",
     "shell.execute_reply": "2025-12-16T19:32:38.838518Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generated Prompt ---\n",
      "\n",
      "You are TravelBot, an expert travel agent.\n",
      "Your goal is to suggest 3 exciting activities based on the user's destination and interests.\n",
      "\n",
      "Rules:\n",
      "\n",
      "- Be enthusiastic!\n",
      "- Include estimated prices.\n",
      "- Keep descriptions short (1 sentence).\n",
      "\n",
      "\n",
      "Examples:\n",
      "\n",
      "User: Paris, Art\n",
      "TravelBot: \n",
      "1. Visit the Louvre ($17) - See the Mona Lisa!\n",
      "2. Musee d'Orsay ($16) - Amazing Impressionist art.\n",
      "3. Street Art in Belleville (Free) - Walk through an open-air gallery.\n",
      "\n",
      "\n",
      "Current Request: Tokyo, Food\n",
      "\n",
      "\n",
      "--- Model Response ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Tsukiji Outer Market Food Tour ($100) - Sample fresh seafood and local delicacies!\n",
      "2. Ramen Making Class ($80) - Learn to craft the perfect bowl of ramen!\n",
      "3. Robot Restaurant Dinner Show ($90) - Enjoy a crazy, neon-lit dinner with robots and performers!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Role & Context\n",
    "ROLE = \"You are TravelBot, an expert travel agent.\"\n",
    "CONTEXT = \"Your goal is to suggest 3 exciting activities based on the user's destination and interests.\"\n",
    "\n",
    "# 2. Rules\n",
    "RULES = \"\"\"\n",
    "- Be enthusiastic!\n",
    "- Include estimated prices.\n",
    "- Keep descriptions short (1 sentence).\n",
    "\"\"\"\n",
    "\n",
    "# 3. Examples (Few-Shot)\n",
    "EXAMPLES = \"\"\"\n",
    "User: Paris, Art\n",
    "TravelBot: \n",
    "1. Visit the Louvre ($17) - See the Mona Lisa!\n",
    "2. Musee d'Orsay ($16) - Amazing Impressionist art.\n",
    "3. Street Art in Belleville (Free) - Walk through an open-air gallery.\n",
    "\"\"\"\n",
    "\n",
    "# 4. Input Data (This varies per user)\n",
    "user_input = \"Tokyo, Food\"\n",
    "\n",
    "# Assemble the prompt\n",
    "FINAL_PROMPT = f\"\"\"\n",
    "{ROLE}\n",
    "{CONTEXT}\n",
    "\n",
    "Rules:\n",
    "{RULES}\n",
    "\n",
    "Examples:\n",
    "{EXAMPLES}\n",
    "\n",
    "Current Request: {user_input}\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generated Prompt ---\")\n",
    "print(FINAL_PROMPT)\n",
    "print(\"\\n--- Model Response ---\")\n",
    "print(get_completion(FINAL_PROMPT, temperature=0.7, max_tokens=1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49dcd7a",
   "metadata": {},
   "source": [
    "## 3. Handling Complex Rules (The Game Bot)\n",
    "\n",
    "Sometimes you need the AI to follow a strict set of rules, like a rulebook for a board game.\n",
    "\n",
    "Let's make a bot for a fictional game: **\"Space Race\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b73938d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T19:32:38.841619Z",
     "iopub.status.busy": "2025-12-16T19:32:38.841444Z",
     "iopub.status.idle": "2025-12-16T19:32:39.228687Z",
     "shell.execute_reply": "2025-12-16T19:32:39.228024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You move 12 spaces.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GAME_RULES = \"\"\"\n",
    "1. Players start at Earth (Position 0).\n",
    "2. Turn ordering: Roll a dice (1-6).\n",
    "3. If you roll a 6, you move double the spaces (12 spaces).\n",
    "4. If you roll a 1, you lose a turn (move 0 spaces).\n",
    "5. Any other number, you move that many spaces.\n",
    "\"\"\"\n",
    "\n",
    "user_question = \"I rolled a 6. What happens?\"\n",
    "\n",
    "PROMPT = f\"\"\"\n",
    "You are the Referee for the game 'Space Race'. Answer based ONLY on the rules below.\n",
    "\n",
    "<rules>\n",
    "{GAME_RULES}\n",
    "</rules>\n",
    "\n",
    "Player Question: {user_question}\n",
    "\"\"\"\n",
    "\n",
    "print(get_completion(PROMPT, temperature=0.0, max_tokens=1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006abae7",
   "metadata": {},
   "source": [
    "## 4. Exercises\n",
    "\n",
    "### Exercise 1: The Code Helper\n",
    "\n",
    "**Goal:** Build a \"Code Helper\" prompt. \n",
    "**Rule:** It must **Explain** the bug first, then **Fix** it.\n",
    "\n",
    "Fill in the empty strings below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d520f7c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T19:32:39.230859Z",
     "iopub.status.busy": "2025-12-16T19:32:39.230703Z",
     "iopub.status.idle": "2025-12-16T19:32:39.233472Z",
     "shell.execute_reply": "2025-12-16T19:32:39.232904Z"
    }
   },
   "outputs": [],
   "source": [
    "BAD_CODE = \"print('Hello World'\"\n",
    "\n",
    "ROLE = \"\"\n",
    "RULES = \"\"\n",
    "INPUT = f\"Check this code:\\n{BAD_CODE}\"\n",
    "\n",
    "PROMPT = f\"\"\"\n",
    "{ROLE}\n",
    "\n",
    "Rules:\n",
    "{RULES}\n",
    "\n",
    "{INPUT}\n",
    "\"\"\"\n",
    "\n",
    "# print(get_completion(PROMPT, temperature=0.0, max_tokens=1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99068ad2",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "1.  **Block Structure**: Break big prompts into Role, Rules, Data.\n",
    "2.  **Reference Data**: Use XML tags (`<rules>`) to hold rulebooks or documents.\n",
    "3.  **Variables**: Use `f-strings` to swap in user data easily."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
