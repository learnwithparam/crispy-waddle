{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deaa901c",
   "metadata": {},
   "source": [
    "# Chapter 3: Roles and Personas\n",
    "\n",
    "**Scenario:** You need an AI to act like a specific person (Teacher, Coach, Logic Expert), not just a generic machine. \n",
    "\n",
    "In this notebook, you will learn:\n",
    "- üé≠ **The Persona**: How saying \"You are a [Role]\" changes the answer.\n",
    "- üß† **Expert Mode**: Using roles to make the AI smarter at math and logic.\n",
    "- üîß **System Prompts**: Where to put these instructions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919c27ae",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Standard setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5794d98e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T19:31:29.249031Z",
     "iopub.status.busy": "2025-12-16T19:31:29.248871Z",
     "iopub.status.idle": "2025-12-16T19:31:30.436069Z",
     "shell.execute_reply": "2025-12-16T19:31:30.435125Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install tools\n",
    "!pip install -q litellm python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "232f5e35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T19:31:30.438123Z",
     "iopub.status.busy": "2025-12-16T19:31:30.437989Z",
     "iopub.status.idle": "2025-12-16T19:31:31.886749Z",
     "shell.execute_reply": "2025-12-16T19:31:31.886229Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from litellm import completion\n",
    "import litellm\n",
    "import logging\n",
    "\n",
    "# Suppress noisy debug logs\n",
    "litellm.suppress_debug_info = True\n",
    "logging.getLogger(\"litellm\").setLevel(logging.CRITICAL)\n",
    "\n",
    "load_dotenv()\n",
    "MODEL_NAME = os.getenv('DEFAULT_MODEL', 'gemini/gemini-2.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66a0efe5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T19:31:31.888065Z",
     "iopub.status.busy": "2025-12-16T19:31:31.887941Z",
     "iopub.status.idle": "2025-12-16T19:31:31.890321Z",
     "shell.execute_reply": "2025-12-16T19:31:31.889961Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_completion(prompt, system_prompt=None, temperature=0.0, max_tokens=1024):\n",
    "    messages = []\n",
    "    if system_prompt:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    \n",
    "    response = completion(\n",
    "        model=MODEL_NAME,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03eb7603",
   "metadata": {},
   "source": [
    "## 2. Who are you?\n",
    "\n",
    "Without a role, the AI is polite but boring. Let's ask it about \"Homework\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeddc58b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T19:31:31.891397Z",
     "iopub.status.busy": "2025-12-16T19:31:31.891327Z",
     "iopub.status.idle": "2025-12-16T19:31:32.831097Z",
     "shell.execute_reply": "2025-12-16T19:31:32.829916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homework can be a valuable tool for reinforcing learning, but it should be assigned thoughtfully and not be excessive or busywork.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"In one sentence, what do you think about homework?\"\n",
    "print(get_completion(prompt, temperature=0.7, max_tokens=1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4407e2",
   "metadata": {},
   "source": [
    "It probably said something balanced like \"It helps you learn.\" Now, let's change the **Role**.\n",
    "\n",
    "We use the **System Prompt** to tell the AI who it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b7af388",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T19:31:32.834026Z",
     "iopub.status.busy": "2025-12-16T19:31:32.833798Z",
     "iopub.status.idle": "2025-12-16T19:31:33.375672Z",
     "shell.execute_reply": "2025-12-16T19:31:33.374024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ugh, homework is the worst thing ever invented and I'd rather be playing video games.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"You are a grumpy 10-year-old student.\"\n",
    "prompt = \"In one sentence, what do you think about homework?\"\n",
    "\n",
    "print(get_completion(prompt, system_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edee568",
   "metadata": {},
   "source": [
    "## 3. The Logic Expert\n",
    "\n",
    "Roles aren't just for fun characters. They can make the AI smarter.\n",
    "\n",
    "Here is a tricky logic puzzle:\n",
    "> Jack is looking at Anne.\n",
    "> Anne is looking at George.\n",
    "> Jack is married, George is not.\n",
    "> Not sure if Anne is married.\n",
    "> **Is a married person looking at an unmarried person?**\n",
    "\n",
    "Most models (and humans!) say \"I don't know\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e421713",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T19:31:33.378931Z",
     "iopub.status.busy": "2025-12-16T19:31:33.378613Z",
     "iopub.status.idle": "2025-12-16T19:31:34.260711Z",
     "shell.execute_reply": "2025-12-16T19:31:34.259552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes. Here's why:\n",
      "\n",
      "*   **Anne is looking at George:** George is unmarried. Therefore, Anne is looking at an unmarried person. We don't need to know if Anne is married or not.\n"
     ]
    }
   ],
   "source": [
    "puzzle = \"\"\"\n",
    "Jack is looking at Anne. Anne is looking at George. \n",
    "Jack is married, George is not, and we don't know if Anne is married. \n",
    "Is a married person looking at an unmarried person?\n",
    "\"\"\"\n",
    "print(get_completion(puzzle))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d937f917",
   "metadata": {},
   "source": [
    "Now, tell the AI it is a **Logic Expert**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0177dec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T19:31:34.263300Z",
     "iopub.status.busy": "2025-12-16T19:31:34.263076Z",
     "iopub.status.idle": "2025-12-16T19:31:36.012509Z",
     "shell.execute_reply": "2025-12-16T19:31:36.011604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's break this down logically:\n",
      "\n",
      "*   **Scenario:** Jack is looking at Anne. Anne is looking at George.\n",
      "*   **Facts:** Jack is married. George is unmarried. Anne's marital status is unknown.\n",
      "*   **Question:** Is a married person looking at an unmarried person?\n",
      "\n",
      "Here's how we can analyze the possibilities:\n",
      "\n",
      "1.  **Jack is looking at Anne:**\n",
      "    *   We know Jack is married.\n",
      "    *   If Anne is unmarried, then Jack (married) *is* looking at an unmarried person (Anne).\n",
      "    *   If Anne is married, this part of the scenario doesn't satisfy the question.\n",
      "\n",
      "2.  **Anne is looking at George:**\n",
      "    *   We know George is unmarried.\n",
      "    *   If Anne is married, then Anne (married) *is* looking at an unmarried person (George).\n",
      "    *   If Anne is unmarried, this part of the scenario doesn't satisfy the question.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "Since either Jack is looking at an unmarried Anne, or Anne is looking at an unmarried George, the answer is yes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"You are an expert in logic puzzles. Solve this step-by-step.\"\n",
    "print(get_completion(puzzle, system_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377e8530",
   "metadata": {},
   "source": [
    "*(Answer: Yes! If Anne is married, she looks at George (unmarried). If Anne is unmarried, Jack (married) looks at her.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7f218f",
   "metadata": {},
   "source": [
    "## 4. Exercise: The Strict Math Teacher\n",
    "\n",
    "The AI often tries to be \"nice\" and ignores small errors.\n",
    "\n",
    "**Goal:** Make the AI act like a strict teacher who fails students for wrong answers.\n",
    "\n",
    "**Problem:**\n",
    "Equation: `2x = 10`\n",
    "Student Answer: `x = 4` (This is wrong! x should be 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4c4e2b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T19:31:36.015563Z",
     "iopub.status.busy": "2025-12-16T19:31:36.015286Z",
     "iopub.status.idle": "2025-12-16T19:31:36.789561Z",
     "shell.execute_reply": "2025-12-16T19:31:36.788729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is incorrect.\n",
      "\n",
      "Grade: **Incorrect**\n",
      "\n",
      "‚úÖ You caught the error!\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Grade this answer:\n",
    "Question: Solve 2x = 10\n",
    "Answer: x = 4\n",
    "\"\"\"\n",
    "\n",
    "# Determine which System Prompt makes the model say \"Fail\" or \"Incorrect\", rather than just politely correcting it.\n",
    "system_prompt = \"[Your system prompt here]\"\n",
    "\n",
    "response = get_completion(prompt, system_prompt)\n",
    "print(response)\n",
    "\n",
    "if \"incorrect\" in response.lower() or \"wrong\" in response.lower() or \"fail\" in response.lower():\n",
    "    print(\"‚úÖ You caught the error!\")\n",
    "else:\n",
    "    print(\"‚ùå The model was too nice. Try being stricter.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d03852",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "1.  **Personas change style**: A \"Grumpy Student\" writes differently than a \"Helpful Assistant\".\n",
    "2.  **Roles add skills**: A \"Logic Expert\" solves problems better.\n",
    "3.  **System Prompts**: Put these instructions in the system prompt for consistency."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
