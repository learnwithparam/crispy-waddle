{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b606a0d7",
   "metadata": {},
   "source": [
    "# Chapter 7: Teaching by Example (Few-Shot)\n",
    "\n",
    "**Scenario:** You have a new intern (the AI). You want them to answer customer emails in a specific, quirky style. You could write a 10-page style guide, OR you could just show them 3 previous emails you wrote and say \"Do it like this\".\n",
    "\n",
    "In this notebook, you'll learn:\n",
    "- 0Ô∏è‚É£ **Zero-Shot**: Asking without examples (the default).\n",
    "- 3Ô∏è‚É£ **Few-Shot**: Proving examples to guide tone and format.\n",
    "- üé® **Style Transfer**: Making the model sound like a pirate, a lawyer, or a soothing parent just by showing it how.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffd499a",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Standard setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd1b9085",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T19:32:17.970127Z",
     "iopub.status.busy": "2025-12-16T19:32:17.969890Z",
     "iopub.status.idle": "2025-12-16T19:32:20.267952Z",
     "shell.execute_reply": "2025-12-16T19:32:20.267471Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q litellm python-dotenv\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from litellm import completion\n",
    "import litellm\n",
    "import logging\n",
    "\n",
    "# Suppress noisy debug logs\n",
    "litellm.suppress_debug_info = True\n",
    "logging.getLogger(\"litellm\").setLevel(logging.CRITICAL)\n",
    "\n",
    "load_dotenv()\n",
    "MODEL_NAME = os.getenv('DEFAULT_MODEL', 'gemini/gemini-2.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2b35a3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T19:32:20.269395Z",
     "iopub.status.busy": "2025-12-16T19:32:20.269269Z",
     "iopub.status.idle": "2025-12-16T19:32:20.271831Z",
     "shell.execute_reply": "2025-12-16T19:32:20.271497Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_completion(prompt, system_prompt=None, prefill=None, temperature=0.0, max_tokens=1024):\n",
    "    messages = []\n",
    "    if system_prompt:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    \n",
    "    if prefill:\n",
    "        messages.append({\"role\": \"assistant\", \"content\": prefill})\n",
    "    \n",
    "    response = completion(\n",
    "        model=MODEL_NAME,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    \n",
    "    if prefill:\n",
    "        return prefill + response.choices[0].message.content\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b81abcd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Zero-Shot vs. Few-Shot\n",
    "\n",
    "**Zero-Shot** is what we've done mostly so far: giving an instruction without examples.\n",
    "\n",
    "Example: \"Will Santa bring me presents?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2277fc74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T19:32:20.272964Z",
     "iopub.status.busy": "2025-12-16T19:32:20.272890Z",
     "iopub.status.idle": "2025-12-16T19:32:21.906203Z",
     "shell.execute_reply": "2025-12-16T19:32:21.904261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whether or not Santa will bring you presents on Christmas depends on a few things! Traditionally, Santa brings presents to children who have been good throughout the year. So, have you been trying your best to be kind, helpful, and well-behaved?\n",
      "\n",
      "Also, do you believe in Santa? A little bit of belief can go a long way!\n",
      "\n",
      "Ultimately, I can't say for sure, but I hope you have a wonderful Christmas, regardless!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_completion(\"Will Santa bring me presents on Christmas?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca43888",
   "metadata": {},
   "source": [
    "The answer is likely factual and boring. But if we're building a \"Parent Bot\", we want magic.\n",
    "\n",
    "**Few-Shot** means giving examples of the input and the desired output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce993db3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T19:32:21.909156Z",
     "iopub.status.busy": "2025-12-16T19:32:21.908890Z",
     "iopub.status.idle": "2025-12-16T19:32:22.770056Z",
     "shell.execute_reply": "2025-12-16T19:32:22.769014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: Absolutely! If you're a good little boy/girl, Santa will definitely be visiting on Christmas Eve.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Please complete the conversation by writing the next line, speaking as \"A\".\n",
    "\n",
    "Q: Is the tooth fairy real?\n",
    "A: Of course, sweetie. Wrap up your tooth and put it under your pillow tonight. There might be something waiting for you in the morning.\n",
    "\n",
    "Q: Will Santa bring me presents on Christmas?\n",
    "\"\"\"\n",
    "\n",
    "print(get_completion(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf328358",
   "metadata": {},
   "source": [
    "By seeing just ONE example of how \"A\" speaks (warm, encouraging, keeping the magic alive), the model mimics it perfectly.\n",
    "\n",
    "## 3. Teaching Formatting\n",
    "\n",
    "Few-shot is also the best way to teach complex output formats without writing a regex manual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "632ade37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T19:32:22.773044Z",
     "iopub.status.busy": "2025-12-16T19:32:22.772840Z",
     "iopub.status.idle": "2025-12-16T19:32:23.543356Z",
     "shell.execute_reply": "2025-12-16T19:32:23.542168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Oliver Hamilton [CHEF]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Extract the person and their profession from the text.\n",
    "\n",
    "Text: Dr. Liam Patel, a neurosurgeon who revolutionized surgical techniques.\n",
    "Output: 1. Dr. Liam Patel [NEUROSURGEON]\n",
    "\n",
    "Text: Olivia Chen was an innovative architect who transformed the village.\n",
    "Output: 2. Olivia Chen [ARCHITECT]\n",
    "\n",
    "Text: Chef Oliver Hamilton has transformed the culinary scene with his farm-to-table restaurant.\n",
    "Output:\n",
    "\"\"\"\n",
    "\n",
    "print(get_completion(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6257a3fd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Exercises\n",
    "\n",
    "### Exercise 1: The Email Classifier (Again)\n",
    "\n",
    "Remember our Email Classifier? It struggled to format the output as just the letter \"(B)\".\n",
    "\n",
    "**Goal:** Use Few-Shot prompting to teach it EXACTLY how to respond. \n",
    "Provide 3 examples of inputs and outputs in the `PROMPT` variable below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21661f61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T19:32:23.546232Z",
     "iopub.status.busy": "2025-12-16T19:32:23.545981Z",
     "iopub.status.idle": "2025-12-16T19:32:24.052657Z",
     "shell.execute_reply": "2025-12-16T19:32:24.051414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: (B)\n",
      "\n",
      "‚úÖ Classification Correct!\n"
     ]
    }
   ],
   "source": [
    "email_to_classify = \"My Mixmaster4000 is smoking. It smells like burning rubber.\"\n",
    "\n",
    "PROMPT = f\"\"\"\n",
    "Classify emails into: (A) Pre-sale, (B) Broken, (C) Billing, (D) Other.\n",
    "\n",
    "Email: Can I paint with this mixer?\n",
    "Class: (A)\n",
    "\n",
    "Email: I want a refund, you charged me twice!\n",
    "Class: (C)\n",
    "\n",
    "Email: How do I turn it on?\n",
    "Class: (D)\n",
    "\n",
    "Email: {email_to_classify}\n",
    "Class:\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(PROMPT)\n",
    "print(response)\n",
    "\n",
    "# Grading\n",
    "if \"(B)\" in response:\n",
    "    print(\"‚úÖ Classification Correct!\")\n",
    "else:\n",
    "    print(\"‚ùå Try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a923f8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "When instructions fail, **use examples**.\n",
    "- It's often faster than writing explanations.\n",
    "- It captures \"soft\" requirements like tone and style.\n",
    "- It enforces strict formatting compliance.\n",
    "\n",
    "In the next chapter, we'll learn how to stop the model from making things up (**Hallucinations**)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
